{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using doc2vec to classify movie reviews\n",
    "Aaron Palumbo | Nov. 8, 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the technique doc2vec to characterize movie reviews as positive or negative. This implementation mostly follows the example in http://districtdatalabs.silvrback.com/modern-methods-for-sentiment-analysis, but it appears there have been changes in the library since  that was written that require changes to some of the symantics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "import gensim.models.doc2vec\n",
    "LabeledSentence = gensim.models.doc2vec.LabeledSentence\n",
    "\n",
    "from collections import OrderedDict\n",
    "import multiprocessing\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from IPython import display as dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6976"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# silly utility to launch a qtconsole when one isn't already running\n",
    "import psutil\n",
    "\n",
    "def returnPyIDs():\n",
    "    pyids = set()\n",
    "    for pid in psutil.pids():\n",
    "        try:\n",
    "            if \"python\" in psutil.Process(pid).name():\n",
    "                pyids.add(pid)\n",
    "        except:\n",
    "            pass\n",
    "    return pyids\n",
    "\n",
    "def launchConsole():\n",
    "    before_pyids = returnPyIDs()\n",
    "    %qtconsole\n",
    "    after_pyids = returnPyIDs()\n",
    "    newid = after_pyids.difference(before_pyids)\n",
    "    assert len(newid) == 1\n",
    "    return list(newid)[0]\n",
    "\n",
    "try:\n",
    "    qtid\n",
    "except NameError:\n",
    "    qtid = launchConsole()\n",
    "    \n",
    "if qtid not in returnPyIDs():\n",
    "    qtid = launchConsole()\n",
    "    \n",
    "qtid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create a list containing the text of each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the data from the link in the Appendix\n",
    "# Reviews\n",
    "reviews = {\n",
    "    \"positive\": {\n",
    "        \"dir\": \"aclImdb/train/pos/\",\n",
    "        \"text\": []\n",
    "    },\n",
    "    \"negative\": {\n",
    "        \"dir\": \"aclImdb/train/neg/\",\n",
    "        \"text\": []\n",
    "    },\n",
    "    \"unsup\": {\n",
    "        \"dir\": \"aclImdb/train/unsup/\",\n",
    "        \"text\": []\n",
    "    }\n",
    "        \n",
    "}\n",
    "\n",
    "# Read files from disk\n",
    "for sentiment in reviews.keys():\n",
    "    d = reviews[sentiment][\"dir\"]\n",
    "    for fileName in os.listdir(d):\n",
    "        with open(os.path.join(d, fileName), \"r\") as f:\n",
    "            reviews[sentiment][\"text\"] += f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure we understand the output of each step as we go along. In the above code we extracted the reviews from all the files and concatenated these into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I admit, the great majority of films released before say 1933 are just not for me. Of the dozen or so \"major\" silents I have viewed, one I loved (The Crowd), and two were very good (The Last Command and City Lights, that latter Chaplin circa 1931).<br /><br />So I was apprehensive about this one, and humor is often difficult to appreciate (uh, enjoy) decades later. I did like the lead actors, but thought little of the film.<br /><br />One intriguing sequence. Early on, the guys are supposed to get \"de-loused\" and for about three minutes, fully dressed, do some schtick. In the background, perhaps three dozen men pass by, all naked, white and black (WWI ?), and for most, their butts, part or full backside, are shown. Was this an early variation of beefcake courtesy of Howard Hughes?',\n",
       " 'Take a low budget, inexperienced actors doubling as production staff\\xc2\\x97 as well as limited facilities\\xc2\\x97and you can\\'t expect much more than \"Time Chasers\" gives you, but you can absolutely expect a lot less. This film represents a bunch of good natured friends and neighbors coming together to collaborate on an interesting project. If your cousin had been one of those involved, you would probably think to yourself, \"ok, this movie is terrible... but a really good effort.\" For all the poorly delivered dialog and ham-fisted editing, \"Time Chasers\" has great scope and ambition... and one can imagine it was necessary to shoot every scene in only one or two takes. So, I\\'m suggesting people cut \"Time Chasers\" some slack before they cut in the jugular. That said, I\\'m not sure I can ever forgive the pseudo-old lady from the grocery store for the worst delivery every wrenched from the jaws of a problematic script.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[\"unsup\"][\"text\"][:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to do some minor cleaning. We will transform all words to lowercase and remove line returns (both '\\n' and '&#60;br />'). We also treat punctuation as individual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Minor cleaning\n",
    "def cleanText(corpus):\n",
    "    punctuation = \"\"\".,?!:;(){}[]\"\"\"\n",
    "    corpus = [z.lower().replace('\\n', '') for z in corpus]\n",
    "    corpus = [z.replace('<br />', ' ') for z in corpus]\n",
    "    \n",
    "    # treat punctuation as individual words\n",
    "    for c in punctuation:\n",
    "        corpus = [z.replace(c, ' {} '.format(c)) for z in corpus]\n",
    "    corpus = [z.split() for z in corpus]\n",
    "    return corpus\n",
    "\n",
    "pos = cleanText(reviews[\"positive\"][\"text\"])\n",
    "neg = cleanText(reviews[\"negative\"][\"text\"])\n",
    "unsup = cleanText(reviews[\"unsup\"][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'admit',\n",
       " ',',\n",
       " 'the',\n",
       " 'great',\n",
       " 'majority',\n",
       " 'of',\n",
       " 'films',\n",
       " 'released',\n",
       " 'before',\n",
       " 'say',\n",
       " '1933',\n",
       " 'are',\n",
       " 'just',\n",
       " 'not',\n",
       " 'for',\n",
       " 'me',\n",
       " '.',\n",
       " 'of',\n",
       " 'the']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsup[0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create results vector\n",
    "# 1 for positive review 0 for negative review\n",
    "y = np.concatenate(\n",
    "    (np.ones(len(pos)), np.zeros(len(neg)))\n",
    ")\n",
    "\n",
    "# Split into training and test set\n",
    "x_train, x_test, y_train, y_test = \\\n",
    "    train_test_split(np.concatenate((pos, neg)), y,\n",
    "                     test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a LabeledSentence object for each review. This is the required by Gensim's Doc2Vec implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def labelizedReviews(reviews, label_type):\n",
    "    labelized = []\n",
    "    for i, v in enumerate(reviews):\n",
    "        label = '{}_{}'.format(label_type, i)\n",
    "        labelized.append(LabeledSentence(words=v, tags=[label]))\n",
    "    return labelized\n",
    "\n",
    "x_train = labelizedReviews(x_train, 'TRAIN')\n",
    "x_test = labelizedReviews(x_test, 'TEST')\n",
    "unsup = labelizedReviews(unsup, 'UNSUP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gensim.models.doc2vec.LabeledSentence'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['i', 'admit', ',', 'the', 'great', 'majority', 'of', 'films', 'released', 'before', 'say', '1933', 'are', 'just', 'not', 'for', 'me', '.', 'of', 'the', 'dozen', 'or', 'so', '\"major\"', 'silents', 'i', 'have', 'viewed', ',', 'one', 'i', 'loved', '(', 'the', 'crowd', ')', ',', 'and', 'two', 'were', 'very', 'good', '(', 'the', 'last', 'command', 'and', 'city', 'lights', ',', 'that', 'latter', 'chaplin', 'circa', '1931', ')', '.', 'so', 'i', 'was', 'apprehensive', 'about', 'this', 'one', ',', 'and', 'humor', 'is', 'often', 'difficult', 'to', 'appreciate', '(', 'uh', ',', 'enjoy', ')', 'decades', 'later', '.', 'i', 'did', 'like', 'the', 'lead', 'actors', ',', 'but', 'thought', 'little', 'of', 'the', 'film', '.', 'one', 'intriguing', 'sequence', '.', 'early', 'on', ',', 'the', 'guys', 'are', 'supposed', 'to', 'get', '\"de-loused\"', 'and', 'for', 'about', 'three', 'minutes', ',', 'fully', 'dressed', ',', 'do', 'some', 'schtick', '.', 'in', 'the', 'background', ',', 'perhaps', 'three', 'dozen', 'men', 'pass', 'by', ',', 'all', 'naked', ',', 'white', 'and', 'black', '(', 'wwi', '?', ')', ',', 'and', 'for', 'most', ',', 'their', 'butts', ',', 'part', 'or', 'full', 'backside', ',', 'are', 'shown', '.', 'was', 'this', 'an', 'early', 'variation', 'of', 'beefcake', 'courtesy', 'of', 'howard', 'hughes', '?'], tags=['UNSUP_0'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(unsup[0]))\n",
    "unsup[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now train two model types:\n",
    "* DM:\n",
    "> DM stands for (D)istributed (M)emory. DM attempts to predict a word given it's previous words\n",
    "\n",
    "* DBOW:\n",
    "> DBOW stands for (D)istributed (B)ag (O)f (W)ords. DBOW predictes a reandom group of words in a paragraph given only it's paragraph vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = 400\n",
    "num_epochs = 10    #~2.5 min / epoch\n",
    "\n",
    "# instantiate our DM annd DBOW models\n",
    "model_dm = gensim.models.Doc2Vec(\n",
    "    min_count=1,\n",
    "    window=10,\n",
    "    size=size,\n",
    "    sample=1e-3,\n",
    "    negative=5,\n",
    "    workers=3\n",
    ")\n",
    "\n",
    "model_dbow = gensim.models.Doc2Vec(\n",
    "    min_count=1,\n",
    "    window=10,\n",
    "    size=size,\n",
    "    sample=1e-3,\n",
    "    negative=5,\n",
    "    dm=0,\n",
    "    workers=3\n",
    ")\n",
    "\n",
    "# build vocab over all reviews\n",
    "model_dm.build_vocab(x_train + x_test + unsup)\n",
    "model_dbow.build_vocab(x_train + x_test + unsup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:supplied example count (70000) did not equal expected count (75000)\n",
      "WARNING:gensim.models.word2vec:supplied example count (70000) did not equal expected count (75000)\n",
      "WARNING:gensim.models.word2vec:supplied example count (70000) did not equal expected count (75000)\n",
      "WARNING:gensim.models.word2vec:supplied example count (70000) did not equal expected count (75000)\n",
      "WARNING:gensim.models.word2vec:supplied example count (70000) did not equal expected count (75000)\n",
      "WARNING:gensim.models.word2vec:supplied example count (70000) did not equal expected count (75000)\n",
      "WARNING:gensim.models.word2vec:supplied example count (70000) did not equal expected count (75000)\n",
      "WARNING:gensim.models.word2vec:supplied example count (70000) did not equal expected count (75000)\n",
      "WARNING:gensim.models.word2vec:supplied example count (70000) did not equal expected count (75000)\n",
      "WARNING:gensim.models.word2vec:supplied example count (70000) did not equal expected count (75000)\n",
      "WARNING:gensim.models.word2vec:supplied example count (70000) did not equal expected count (75000)\n",
      "WARNING:gensim.models.word2vec:supplied example count (70000) did not equal expected count (75000)\n",
      "WARNING:gensim.models.word2vec:supplied example count (70000) did not equal expected count (75000)\n",
      "WARNING:gensim.models.word2vec:supplied example count (70000) did not equal expected count (75000)\n",
      "WARNING:gensim.models.word2vec:supplied example count (70000) did not equal expected count (75000)\n",
      "WARNING:gensim.models.word2vec:supplied example count (70000) did not equal expected count (75000)\n",
      "WARNING:gensim.models.word2vec:supplied example count (70000) did not equal expected count (75000)\n",
      "WARNING:gensim.models.word2vec:supplied example count (70000) did not equal expected count (75000)\n",
      "WARNING:gensim.models.word2vec:supplied example count (70000) did not equal expected count (75000)\n",
      "WARNING:gensim.models.word2vec:supplied example count (70000) did not equal expected count (75000)\n"
     ]
    }
   ],
   "source": [
    "# in training the model, it is recommended to train over\n",
    "# the data multiple times while randomizing the input order\n",
    "all_training_reviews = x_train + unsup\n",
    "for epoch in xrange(num_epochs):\n",
    "    perm = np.random.permutation(len(all_training_reviews))\n",
    "    model_dm.train([all_training_reviews[i] for i in perm])\n",
    "    model_dbow.train([all_training_reviews[i] for i in perm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get training set vectors\n",
    "def getVecs(model, corpus, size):\n",
    "    vecs = [np.array(model.docvecs[z.tags[0]]).reshape((1, size)) for z in corpus]\n",
    "    return np.concatenate(vecs)\n",
    "\n",
    "train_vecs_dm = getVecs(model_dm, x_train, size)\n",
    "train_vecs_dbow = getVecs(model_dbow, x_train, size)\n",
    "\n",
    "train_vecs = np.hstack((train_vecs_dm, train_vecs_dbow))\n",
    "\n",
    "# Build test vectors\n",
    "test_vecs_dm = getVecs(model_dm, x_test, size)\n",
    "test_vecs_dbow = getVecs(model_dbow, x_test, size)\n",
    "\n",
    "test_vecs = np.hstack((test_vecs_dm, test_vecs_dbow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to build a simple linear model, train it on our training set and measure  performance on our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.50\n"
     ]
    }
   ],
   "source": [
    "lr = SGDClassifier(loss='log', penalty='l1')\n",
    "lr.fit(train_vecs, y_train)\n",
    "\n",
    "print 'Test Accuracy: {:.2f}'.format(lr.score(test_vecs, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not very good, and it is significantly less than te accuracy reported by similar attempts to classify the same database, which are achieving upwards of 87%. I must conclude that there is a mistake somewhere in my process, but I have been unable to find it.\n",
    "\n",
    "(I tested the model using an SVM and saw the same results, so there is something in the way I am constructing the document vectors.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data:\n",
    "* http://ai.stanford.edu/%7Eamaas/data/sentiment/\n",
    "\n",
    "#### Methodology:\n",
    "* http://cs.stanford.edu/~quocle/paragraph_vector.pdf\n",
    "* http://districtdatalabs.silvrback.com/modern-methods-for-sentiment-analysis\n",
    "* https://github.com/piskvorky/gensim/blob/develop/docs/notebooks/doc2vec-IMDB.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### doc2vec documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " class gensim.models.doc2vec.Doc2Vec(documents=None, size=300, alpha=0.025, window=8, min_count=5, max_vocab_size=None, sample=0, seed=1, workers=1, min_alpha=0.0001, dm=1, hs=1, negative=0, dbow_words=0, dm_mean=0, dm_concat=0, dm_tag_count=1, docvecs=None, docvecs_mapfile=None, comment=None, trim_rule=None, **kwargs)\n",
    "\n",
    "    Bases: gensim.models.word2vec.Word2Vec\n",
    "\n",
    "    Class for training, using and evaluating neural networks described in http://arxiv.org/pdf/1405.4053v2.pdf\n",
    "\n",
    "    Initialize the model from an iterable of documents. Each document is a TaggedDocument object that will be used for training.\n",
    "\n",
    "    The documents iterable can be simply a list of TaggedDocument elements, but for larger corpora, consider an iterable that streams the documents directly from disk/network.\n",
    "\n",
    "    If you don’t supply documents, the model is left uninitialized – use if you plan to initialize it in some other way.\n",
    "\n",
    "    dm defines the training algorithm. By default (dm=1), ‘distributed memory’ (PV-DM) is used. Otherwise, distributed bag of words (PV-DBOW) is employed.\n",
    "\n",
    "    size is the dimensionality of the feature vectors.\n",
    "\n",
    "    window is the maximum distance between the predicted word and context words used for prediction within a document.\n",
    "\n",
    "    alpha is the initial learning rate (will linearly drop to zero as training progresses).\n",
    "\n",
    "    seed = for the random number generator. Only runs with a single worker will be deterministically reproducible because of the ordering randomness in multi-threaded runs.\n",
    "\n",
    "    min_count = ignore all words with total frequency lower than this.\n",
    "\n",
    "    max_vocab_size = limit RAM during vocabulary building; if there are more unique words than this, then prune the infrequent ones. Every 10 million word types need about 1GB of RAM. Set to None for no limit (default).\n",
    "\n",
    "    sample = threshold for configuring which higher-frequency words are randomly downsampled;\n",
    "        default is 0 (off), useful value is 1e-5.\n",
    "\n",
    "    workers = use this many worker threads to train the model (=faster training with multicore machines).\n",
    "\n",
    "    hs = if 1 (default), hierarchical sampling will be used for model training (else set to 0).\n",
    "\n",
    "    negative = if > 0, negative sampling will be used, the int for negative specifies how many “noise words” should be drawn (usually between 5-20).\n",
    "\n",
    "    dm_mean = if 0 (default), use the sum of the context word vectors. If 1, use the mean. Only applies when dm is used in non-concatenative mode.\n",
    "\n",
    "    dm_concat = if 1, use concatenation of context vectors rather than sum/average; default is 0 (off). Note concatenation results in a much-larger model, as the input is no longer the size of one (sampled or arithmatically combined) word vector, but the size of the tag(s) and all words in the context strung together.\n",
    "\n",
    "    dm_tag_count = expected constant number of document tags per document, when using dm_concat mode; default is 1.\n",
    "\n",
    "    dbow_words if set to 1 trains word-vectors (in skip-gram fashion) simultaneous with DBOW doc-vector training; default is 0 (faster training of doc-vectors only).\n",
    "\n",
    "    trim_rule = vocabulary trimming rule, specifies whether certain words should remain\n",
    "\n",
    "        in the vocabulary, be trimmed away, or handled using the default (discard if word count < min_count). Can be None (min_count will be used), or a callable that accepts parameters (word, count, min_count) and returns either util.RULE_DISCARD, util.RULE_KEEP or util.RULE_DEFAULT. Note: The rule, if given, is only used prune vocabulary during build_vocab() and is not stored as part\n",
    "\n",
    "            of the model.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
